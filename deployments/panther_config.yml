# Panther is a Cloud-Native SIEM for the Modern Security Team.
# Copyright (C) 2020 Panther Labs Inc
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU Affero General Public License as
# published by the Free Software Foundation, either version 3 of the
# License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>.

##### Panther deployment configuration #####

Infra:
  # Comma-delimited list of LayerVersions to attach to every Lambda function.
  #
  # For example, this could be a serverless monitoring/security service.
  BaseLayerVersionArns: ''

  # Allow HTTP(S) ingress access to the web app (ALB) security group from this IP block.
  # Use 0.0.0.0/0 to allow unrestricted access
  LoadBalancerSecurityGroupCidr: 0.0.0.0/0

  # These optional settings will allow you to deploy the panther load balancer into a security group
  # And VPC of your choice. If you set VpcID, you must also set SecurityGroupID and ensure the
  # subnet IP ranges are valid & available.
  #
  # SubnetOneID and SubnetTwoID are optional. These options supersede the SubnetOneIPRange and SubnetTwoIPRange
  # parameters, if you specify IDs then the IP ranges are ignored.
  VpcID: ''
  # These values only take affect if VpcID is specified
  SecurityGroupID: ''
  SubnetOneID: ''
  SubnetTwoID: ''
  SubnetOneIPRange: '172.31.250.0/26' # By default, this IP range should be available in the default VPC
  SubnetTwoIPRange: '172.31.251.0/26' # By default, this IP range should be available in the default VPC

  # Lambda functions scale memory and CPU together.
  # Those with the smallest memory are slower and cheaper.
  # Those with the larger memory are faster and more expensive.
  # If cost is more of a concern compared to performance, choose
  # a small memory size, however, for extremely large log volumes
  # the larger sizes may be required for adequate performance or large files.
  # https://aws.amazon.com/lambda/pricing/
  # Processing capability can be further increased by raising the
  # Lambda concurrent execution limit from default 1000, see:
  # https://docs.aws.amazon.com/lambda/latest/dg/gettingstarted-limits.html
  LogProcessorLambdaMemorySize: 1024 # 256 - 10240, in 1MB increments

  # The log processor reads in batches of S3 notifications from an SQS queue.
  # In order to keep SQS API costs down we default to the largest allowed batch size. However,
  # if there are large numbers of very large files then the lambda may not
  # finish the work within the deadline and timeout. If this happening, reduce
  # this value. If timeouts persist when set to 1, then the files are likely too large to be processed.
  LogProcessorLambdaSQSReadBatchSize: 10

  # Create a Python layer with these pip library versions for analysis and remediation.
  #
  # "mage deploy" will download and package these libraries, generating the "out/layer.zip" file.
  # Natively compiled libraries (e.g. numpy) must be deployed from linux to work correctly, or
  # you can provide your own custom layer via PythonLayerVersionArn.
  #
  # This setting has no effect if PythonLayerVersionArn is set below.
  PipLayer:
    - jsonpath-ng==1.5.2
    - policyuniverse==1.3.2.2
    - requests==2.23.0

  # Enable provisioned capacity and autoscaling for the key-value Dynamo store available to the Python engines.
  # You may want to enable this if you make a high volume of requests to the key-value store, but otherwise
  # the default (pay-per-request) billing is typically cheaper for small-to-medium workloads
  # This setting can only be changed once every 24 hours
  KvTableBillingMode: PAY_PER_REQUEST # PROVISIONED or PAY_PER_REQUEST

  # Custom layer attached to every Python Lambda function for analysis and remediation.
  #
  # If not specified, a layer is created for you based on the PipLayer setting above.
  PythonLayerVersionArn: ''

  # A managed IAM policy which will be attached to the Python rules-engine and policy-engine.
  #
  # This lets your rules and policies interact with any AWS infrastructure you would like.
  PythonManagedPolicyArn: ''

  # A list of IAM roles which the Python rules-engine and policy-engine will be allowed to assume.
  #
  # You could instead create a managed policy and use the PythonManagedPolicyArn setting, above.
  # But if you just need to assume a role, specifying it here requires no additional infrastructure;
  # it will update the inline IAM policy for the Python engines.
  #
  # For example, you could give the Python engines permission to assume the audit role used for
  # cloud security scanning.
  PythonAssumableRoleArns: []

Monitoring:
  # This is the arn for the SNS topic you want associated with Panther system alarms.
  # If this is not set alarms will be associated with the SNS topic `panther-alarms`.
  AlarmSnsTopicArn: ''

  # Retention period for all Panther CloudWatch log groups.
  CloudWatchLogRetentionDays: 365

  # Enable DEBUG logging for all Lambda functions.
  Debug: false

  # XRay tracing mode for API Gateway and Lambda: '', 'Active', or 'PassThrough'
  TracingMode: ''

Setup:
  # The company name/email displayed in Settings > General (not used anywhere else today)
  Company:
    DisplayName: AwesomeCo
    Email: user@example.com

  # The first Panther user. If left blank, you will be prompted for this when you deploy.
  FirstUser:
    GivenName: ''
    FamilyName: ''
    Email: ''

  # List of policy/rule sets to install when Panther is first deployed.
  #
  # Entries must be URLs that point to a .zip file.
  # After the first deployment, you can use the BulkUpload functionality from the web app
  # to upload new or modified rule sets.
  InitialAnalysisSets:
    - https://github.com/panther-labs/panther-analysis/releases/latest/download/panther-analysis-all.zip

  # Enable S3 access logs for Panther buckets.
  # Doing so is a strongly recommend security practice, but can come at a high cost
  # when processing large volumes of data.
  #
  # Access logs are sent either to the S3AccessLogsBucket below or a the panther audit bucket created for you.
  EnableS3AccessLogs: true

  # Optionally use an existing S3 bucket name for storing S3 access logs.
  # If not specified, the generated panther audit logs bucket is used for access logs as well.
  #
  # Has no effect if EnableS3AccessLogs=false above.
  S3AccessLogsBucket: ''

  # If specified, user data is replicated to this bucket arn.
  DataReplicationBucket: ''

  # Whether or not the Panther deployment should automatically onboard itself as a data source.
  OnboardSelf: true

  # Whether or not to create a CloudTrail in the Panther account and monitor.
  # You may want this off if you have org-level CT configured for Panther to avoid ingesting the same data twice.
  EnableCloudTrail: false

  # Whether or not to enable GuardDuty in the Panther account and monitor.
  # You may want this off if you have org-level GD configured for Panther.
  EnableGuardDuty: false

  # Grant external access to the Panther processed data.
  LogSubscriptions:
    # A list of ARNs of Principals that want to subscribe to log data.
    # These ARNs will be granted read permission on the processed log bucket and
    # SNS subscribe permission to the panther-processed-data-notifications topic.
    # For example:
    # PrincipalARNs:
    #   - arn:aws:iam::123456789012:role/mysystem-access
    #   - arn:aws:iam::123456789012:user/mysystem-iam-user
    PrincipalARNs:

Web:
  # ARN of an AWS ACM certificate used on the loadbalancer presenting the panther web app
  #
  # If not specified, a self signed certificate is created automatically.
  # WARNING: SELF SIGNED CERTIFICATES ARE NOT SAFE TO USE IN PRODUCTION, PLEASE
  # PROVIDE A CERTIFICATE FOR PRODUCTION USE
  CertificateArn: ''

  # Domain that you own and have configured to alias to the default load balancer URL
  #
  # If not specified, the default load balancer URL is used in all places.
  CustomDomain: ''
